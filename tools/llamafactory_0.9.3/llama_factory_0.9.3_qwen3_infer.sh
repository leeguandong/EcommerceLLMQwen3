export CUDA_VISIBLE_DEVICES=3,4,5,6
llamafactory-cli chat "/home/gdli7/SparkLLM/tools/llamafactory_0.9.3/inference/qwen3_lora_sft.yaml"